{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH12 Hash Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some important notes:\n",
    "# A hash table is a data structure used to store keys, optionally, with corresponding values. Inserts, deletes and lookups run in O(1) time on average.\n",
    "# Compared to binary search trees, inserting and deleting in a hash table is more efficient\n",
    "# If you want to update a key in a hash table, first delete it and then update it\n",
    "# As a rule of thumb, avoid using mutable objects as keys\n",
    "# Hash table can be represented using a dictionary. Trie which is a tree data structure can also be used => unlike BST, nodes in the tree do not store a key. Instead, the nodes's position in the tree defines the key which it is associated with.\n",
    "# Hash tables have best theoretical and real world performance for lookup, insert and delete=>Avg Time Complexity: O(1)\n",
    "# A single insert can take O(n) if the hash table has to be resized\n",
    "# The following are the properties of hash table libraries in Python:\n",
    "# - Common hashtable data structures in python are: set, dict, collections.defaultdict, collections.counter => set stores only keys whereas others store key-value pairs\n",
    "# - a collections.defaultdict returns the default value of the type that was specified when the collection was instantiated,e.g.,ifd = collections.defaultdict(list),thenif k not in d[k] is []\n",
    "# - collections.counter is used for counting the number of occurences of keys \n",
    "# - The most important operations for set are s.add(42),s.remove(42),s.discard(123),x in s, as well as s <= t (is s a subsetof t), and s - t (elements in s that are not in t).\n",
    "# - In key-value collections, to iterate over keys-value pair iterate over items()\n",
    "# Only immutable data types can act as keys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An application of hash tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The groups of anagrams are:[['debitcard', 'badcredit'], ['elvis', 'lives', 'levis'], ['silent', 'listen']]\n"
     ]
    }
   ],
   "source": [
    "# Anagrams are popular word play puzzels, whereby rearranging letters of one set of words, you get another set of words.\n",
    "\n",
    "# Task: Test if one word is anagram of another\n",
    "# Sol: Sort both words, if they result in equal string after sorting then they are anagrams\n",
    "# Time Complexity: O(mlogm) where m is the length of the string\n",
    "\n",
    "# Task: write a program that takes as input a set of words and retums groups of anagrams for those words.\n",
    "# Brute Force: Take each word -> sort it-> compare it with all other words => Time Complexity = O(n^2*m*logm)\n",
    "# Optimized: Take each string -> sort it-> add the sorted string as a key to the dict if it is not already present\n",
    "\n",
    "import collections\n",
    "# Time Complexity: O(nmlogm) to sort n strings + O(nm) for insertions => O(nmlogn)\n",
    "def find_anagrams(input_list):\n",
    "    sorted_strings_to_anagrams = collections.defaultdict(list) # creates a dict where values of each key are stored in a list\n",
    "    for s in input_list:\n",
    "        #print(sorted(s))\n",
    "        sorted_strings_to_anagrams[''.join(sorted(s))].append(s)\n",
    "    \n",
    "    return [group for group in sorted_strings_to_anagrams.values() if len(group) >= 2]\n",
    "\n",
    "input_list = ['debitcard', 'elvis', 'silent', 'badcredit', 'lives', 'freedom', 'listen', 'levis', 'money']\n",
    "print(f'The groups of anagrams are:{find_anagrams(input_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The groups of anagrams are:[['debitcard', 'badcredit'], ['elvis', 'lives', 'levis'], ['silent', 'listen']]\n"
     ]
    }
   ],
   "source": [
    "# Variant: Design an O(nm) algorithm for the same problem, assuming strings are made up of lower case English characters.\n",
    "# Sol: HashMap<HashMap, ArrayList> here the inner hashmap is used to store the freq of each char which acts as key for the outer hash map\n",
    "# Ref: https://www.geeksforgeeks.org/given-a-sequence-of-words-print-all-anagrams-together/\n",
    "\n",
    "def find_anagrams_lower(input_list):\n",
    "    sorted_strings_to_anagrams = collections.defaultdict(list)\n",
    "    for s in input_list:\n",
    "        # Creating inner hashmap for each string to store the freq of each char\n",
    "        char_freq_map = collections.defaultdict(int)\n",
    "        for c in s:\n",
    "            char_freq_map[c] += 1\n",
    "        # Adding string to the outer dict\n",
    "        key_present = False\n",
    "        for k in sorted_strings_to_anagrams.keys():\n",
    "            if char_freq_map == dict(k):\n",
    "                key_present = True\n",
    "                sorted_strings_to_anagrams[k].append(s)\n",
    "        if not key_present: \n",
    "            sorted_strings_to_anagrams[tuple(char_freq_map.items())].append(s) # dict cannot be key to another dict so converting it to tuple\n",
    "            \n",
    "    return [group for group in sorted_strings_to_anagrams.values() if len(group) >= 2]\n",
    "\n",
    "input_list = ['debitcard', 'elvis', 'silent', 'badcredit', 'lives', 'freedom', 'listen', 'levis', 'money']\n",
    "print(f'The groups of anagrams are:{find_anagrams_lower(input_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design of a hashable class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider a class that represents contacts. For simplicity, assume each contact is a string. Suppose\n",
    "# it is a hard requirement that the individual contacts are to be stored in a list and it's possible that\n",
    "# the list contains duplicates. Two contacts should be equal if they contain the same set of strings,\n",
    "# regardless of the ordering of the strings within the underlying list. Multiplicity is not important,\n",
    "# i.e., three repetitions of the same contact is the same as a single instance of that contact\n",
    "\n",
    "# We have to create a hashable class and define our own methods for equal operation\n",
    "class ContactList:\n",
    "    def __init__(self, names):\n",
    "        self.names = names\n",
    "    \n",
    "    # Time Complexity: O(n) where n is the number of strings in the list\n",
    "    def __hash__(self):\n",
    "        # we would like to convert list to set to avoid duplicates and then hash the set\n",
    "        # But set is a mutable data type so it cannot be hashed => we can use frozenset instead\n",
    "        return hash(frozenset(self.names))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return set(self.names) == set(other.names)\n",
    "\n",
    "# Task: Merge all contacts to a single list\n",
    "def merge_contact_list(contacts):\n",
    "    return list(set(contacts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collections.Counter Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter for the given list:Counter({2: 4, 1: 3, 3: 3, 4: 2, 5: 1})\n",
      "c+d:Counter({'a': 4, 'b': 3})\n",
      "c-d:Counter({'a': 2})\n",
      "c&d:Counter({'a': 1, 'b': 1})\n",
      "c|d:Counter({'a': 3, 'b': 2})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "myList = [1, 1, 2, 3, 4, 5, 2, 3, 4, 2, 1, 2, 3]\n",
    "print(f'Counter for the given list:{Counter(myList)}')\n",
    "c = Counter(a=3, b=1)\n",
    "d = Counter(a=1, b=2)\n",
    "print(f'c+d:{c+d}') # adding two counters\n",
    "print(f'c-d:{c-d}') # subtract (keep only positive counts)\n",
    "print(f'c&d:{c&d}') # intersection: min(c[x], d[x]) \n",
    "print(f'c|d:{c|d}') # union: max(c[x], d[x]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 Test for palindromic permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'e': 2, 'd': 2, 'i': 2, 'f': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task: Write a program to test whether the letters forming a string can be permuted to form a palindrome.\n",
    "# For example, \"edified\" can be permuted to form \"deified\".\n",
    "\n",
    "# Brute Force: Generate all permutations of the input string and then test each for palindromicity\n",
    "# Optimized: In order to be a palindrome, all chars should appear even no.of time or at most one char can appear odd no.of times\n",
    "\n",
    "# Time Complexity: O(N)\n",
    "def can_get_palindrome(string):\n",
    "    # return sum(v % 2 for v in Counter(string).values()) <= 1 # code given in book\n",
    "    char_counter = Counter(string)\n",
    "    #print(char_counter)\n",
    "    odd_count_chars = {}\n",
    "    for key, value in char_counter.items():\n",
    "        if value % 2 == 1:\n",
    "            odd_count_chars[key] = value\n",
    "            if len(odd_count_chars) > 1:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "string = 'edified'\n",
    "can_get_palindrome(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 Is an anonymous letter constructible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is ababab constructible from ababab:True\n",
      "Pythonic Is ababab constructible from ababab:True\n",
      "Is ababab constructible from abababc:True\n",
      "Pythonic Is ababab constructible from abababc:True\n",
      "Is abababc constructible from ababab:False\n",
      "Pythonic Is abababc constructible from ababab:False\n"
     ]
    }
   ],
   "source": [
    "# Task: Write a program which takes text for an anonymous letter and text for a magazine and determines if it is possible to write the anonymous letter using the magazine. \n",
    "# The anonymous letter can be written using the magazine if for each character in the anonymous letter, the number of times it appears in the anonymous letter is no more than the number of times it appears in the magazine.\n",
    "# Brute Force: Count the number of occurences of each charachter by parsing the letter and magazine multiple times.\n",
    "import collections\n",
    "# Better Approach: Pass the letter once and build a hash table then decrement the count of each char while parsing the magazine\n",
    "# Time Complexity: O(m+n) Space complexity: size of the hash table => O(L)\n",
    "# If the chars are ASCII encoded, then we can eliminate hash table and just use an integer array of size 256.\n",
    "def is_letter_constructible_from_magazine(letter, magazine):\n",
    "    char_freq_for_letter = collections.Counter(letter) # builds a hash table for each occurence of the char in letter\n",
    "    \n",
    "    for c in magazine:\n",
    "        if c in char_freq_for_letter:\n",
    "            char_freq_for_letter[c] -= 1\n",
    "            if char_freq_for_letter[c] == 0:\n",
    "                del char_freq_for_letter[c]\n",
    "                if not char_freq_for_letter:\n",
    "                    return True\n",
    "    \n",
    "    return not char_freq_for_letter\n",
    "\n",
    "def is_letter_constructible_from_magazine_pythonic(letter, magazine):\n",
    "    return not (collections.Counter(letter) - collections.Counter(magazine))\n",
    "\n",
    "letter = \"ababab\"\n",
    "magazine = \"ababab\"\n",
    "print(f'Is {letter} constructible from {magazine}:{is_letter_constructible_from_magazine(letter, magazine)}')\n",
    "print(f'Pythonic Is {letter} constructible from {magazine}:{is_letter_constructible_from_magazine_pythonic(letter, magazine)}')\n",
    "letter = \"ababab\"\n",
    "magazine = \"abababc\"\n",
    "print(f'Is {letter} constructible from {magazine}:{is_letter_constructible_from_magazine(letter, magazine)}')\n",
    "print(f'Pythonic Is {letter} constructible from {magazine}:{is_letter_constructible_from_magazine_pythonic(letter, magazine)}')\n",
    "letter = \"abababc\"\n",
    "magazine = \"ababab\"\n",
    "print(f'Is {letter} constructible from {magazine}:{is_letter_constructible_from_magazine(letter, magazine)}')\n",
    "print(f'Pythonic Is {letter} constructible from {magazine}:{is_letter_constructible_from_magazine_pythonic(letter, magazine)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.3 Implement an ISBN cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(1, 1)])\n",
      "OrderedDict([(2, 2), (1, 1)])\n",
      "OrderedDict([(1, 1), (2, 2)])\n",
      "OrderedDict([(3, 3), (1, 1)])\n",
      "OrderedDict([(3, 3), (1, 1)])\n",
      "OrderedDict([(4, 4), (3, 3)])\n",
      "OrderedDict([(4, 4), (3, 3)])\n",
      "OrderedDict([(3, 3), (4, 4)])\n",
      "OrderedDict([(4, 4), (3, 3)])\n"
     ]
    }
   ],
   "source": [
    "# The Intemational Standard Book Number (ISBN) is a unique commercial book identifier. It is a string of length 10. The first 9 characters are digits; the last character is a check character. The check character is the sum of the first 9 digits, mod 11, with 10 represented by 'X'.\n",
    "# Task: Create a cache for looking up prices of books identified by their ISBN. You implement lookup, insert, and remove methods. Use the Least Recently Used (LRU) policy for cache eviction. \n",
    "# If an ISBN is already present, insert should not change the price, but it should update that entry to be the most recently used entry. Lookup should also update that entry to be the most recently used entry.\n",
    "\n",
    "# Hash tables are ideal for lookup. we need to create a hash table with ISBN as key with {price, least recent time a lookup was done} as values.\n",
    "# Insert takes O(1), lookup takes O(1), once the cache is full we have to find the entry which is not recently used - O(n) where n is the size of the cache\n",
    "\n",
    "# One way to improve performance is to use lazy garbage collection. If we want a cache of size n, we will not delete any entries until the hash table size grows to 2n entries.\n",
    "# Drawback: O(n) increase in memory, O(n) time needed for lookups that miss on a full cache\n",
    "\n",
    "# Optimized approach: Keys Queue using linked list + Hash table stores location of each key in the queue\n",
    "# An altemative is to maintain a separate queue of keys. In the hash table we store for each key a reference to its location in the queue. \n",
    "# Each time an ISBN is looked up and is found in the hash table, it is moved to the front of the queue. (This requires us to use a linked list implementation of the queue, so that items in the middle of the queue can be moved to the head.) \n",
    "# Then the length of the queue exceeds n,when a new element is added to the cache, the item at the tail of the queue is deleted from the cache, i.e., from the queue and the hash table.\n",
    "# Time complexity: Lookup - O(1) for the hash table lookup, O(1) - for updating the queue. So, all operations take O(1) time complexity\n",
    "# Positions:\n",
    "# - recently lookedup or inserted element will be present at the beginning of the linked list => left\n",
    "# - least recently lookedup element will be present at the end of the linked list =>right\n",
    "class LRUCache:\n",
    "    def __init__(self, capacity):\n",
    "        # Ordered dict-{key:reference_to_position_of_key_in_circular_doubly_linked_list}\n",
    "        # Ref: https://stackoverflow.com/questions/33748340/how-does-pythons-ordereddict-remember-elements-inserted\n",
    "        # Ref: https://hg.python.org/cpython/file/2.7/Lib/collections.py \n",
    "        # ordered_dict[key] = [PREV, NEXT, KEY] the key in the list holds the value\n",
    "        self._isbn_price_table = collections.OrderedDict()\n",
    "        self._capacity = capacity\n",
    "    \n",
    "    def lookup(self, isbn):\n",
    "        if isbn not in self._isbn_price_table:\n",
    "            return -1\n",
    "        # Logic given in book - but I think this will insert the isbn at the end whereas we want the isbn at the beginning\n",
    "        #price = self._isbn_price_table.pop(isbn) # removing isbn\n",
    "        #self._isbn_price_table[isbn] = price # then inserting it again - \n",
    "        \n",
    "        # we can move the key to the front \n",
    "        # Ref: https://docs.python.org/3/library/collections.html#collections.OrderedDict.move_to_end\n",
    "        self._isbn_price_table.move_to_end(isbn, last = False) # moving key to the beginning\n",
    "        return self._isbn_price_table[isbn] # returning value\n",
    "    \n",
    "    def insert(self, isbn, price):\n",
    "        if isbn in self._isbn_price_table:\n",
    "            return lookup(self, isbn) \n",
    "        elif self._capacity <= len(self._isbn_price_table):\n",
    "            self._isbn_price_table.popitem() # removes the last entry\n",
    "        \n",
    "        self._isbn_price_table[isbn] = price # inserting an element at the end \n",
    "        self._isbn_price_table.move_to_end(isbn, last = False) # moving it to the beginning \n",
    "            \n",
    "    def erase(self, isbn):\n",
    "        return self._isbn_price_table.pop(isbn, None) is not None\n",
    "    \n",
    "cache = LRUCache(2)\n",
    "cache.insert(1, 1)\n",
    "print(cache._isbn_price_table)\n",
    "cache.insert(2, 2)\n",
    "print(cache._isbn_price_table)\n",
    "cache.lookup(1)\n",
    "print(cache._isbn_price_table)\n",
    "cache.insert(3, 3)\n",
    "print(cache._isbn_price_table)\n",
    "cache.lookup(2)\n",
    "print(cache._isbn_price_table)\n",
    "cache.insert(4, 4)\n",
    "print(cache._isbn_price_table)\n",
    "cache.lookup(1)\n",
    "print(cache._isbn_price_table)\n",
    "cache.lookup(3)\n",
    "print(cache._isbn_price_table)\n",
    "cache.lookup(4)\n",
    "print(cache._isbn_price_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.4 Compute the LCA, optimizing for close ancestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design an algorithm for computing the LCA of two nodes in a binary tree. \n",
    "# The algorithm's time complexity should depend only on the distance from the nodes to the LCA.\n",
    "\n",
    "# Approach: Traverse up from node1 and store the visited nodes in the hash table. Simultaneously, traverse up from node and check if the node is already present in the hash table if not insert it.\n",
    "# Time Complexity: O(h) Space Complexity:O(D0 + D1) where D0 is the distance from the LCA to the first node and D1 is the distance to the second node.\n",
    " \n",
    "# But the approach specified in 9.4 uses Time Complexity:O(h) and Space Complexity:O(1) - which is better than hash table so not implementing it here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.5 Find the nearest repeated entries in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smalles distance is 2\n"
     ]
    }
   ],
   "source": [
    "# Write a program which takes as input an array and finds the distance between a closest pair of equal entries. \n",
    "# For example, if s = <\"All\", \"work\", \"and\", \"no\", \"play\", \"makes\", \"for\", \"no\", \"work\", \"no\", \"fun\",\"and\", \"no\", \"results\">, \n",
    "# then the second and third occurrences of \"no\" is the closest Pair.\n",
    "\n",
    "# Brute Force: Iterate over all pairs of entries -> check if they are same -> update min distance if it is smalles than the curr values.\n",
    "# Time Complexity: O(N)\n",
    "\n",
    "# Approach: We can store the set of indices corresponding to a given value using a hash table and iterate over all such sets.\n",
    "# Optimized approach: Just store the latest index of the element in the hash table instead of all the indices.\n",
    "# Time Complexity: O(n) Space Complexity: O(d) where d is the number of distinct entries in the array\n",
    "def find_nearest_repetition(paragraph):\n",
    "    word_to_latest_index, nearest_repeated_distance = {}, float('+inf')\n",
    "    for i, word in enumerate(paragraph.split(\" \")):\n",
    "        #print(f'i={i} word={word}')\n",
    "        if word in word_to_latest_index:\n",
    "            latest_ind = word_to_latest_index[word]\n",
    "            nearest_repeated_distance = min(nearest_repeated_distance, i - latest_ind)\n",
    "        word_to_latest_index[word] = i\n",
    "    return nearest_repeated_distance if nearest_repeated_distance != float('+inf') else -1\n",
    "\n",
    "s = \"All work and no play makes for no work no fun and no results\"\n",
    "print(f'The smalles distance is {find_nearest_repetition(s)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.6 Find the smallest subarray covering all values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest subarray is (8, 10)\n"
     ]
    }
   ],
   "source": [
    "# Write a program which takes an array of strings and a set of strings, and return the indices of the starting and ending index of a shortest subarray of the given array that \"covers\" the set, i.e., contains all strings in the set.\n",
    "# Brute Force: Iterate over all subarays and test if the subarray contains all strings in the set. \n",
    "# - If the array size is n => number of subarrays is O(n^2). \n",
    "# - Testing if the subarray covers the set is O(n) using hash table\n",
    "# - Overall Time complexity: O(n^3)\n",
    "\n",
    "# Approach: At index i, store which strings in the set remain to be covered and then increase the length of the subarray - stop immediately once the set is covered.\n",
    "# we can further improve by using the work done at i while calculating for i+1\n",
    "# use the concept of two pointers left, right => right keeps incrementing in for loop, left increments until it covers the set\n",
    "# Time Complexity: O(n) => both left and right pointer can increment at most n times so this algo has linear time complexity.\n",
    "Subarray = collections.namedtuple('Subarray', ('start', 'end'))\n",
    "def find_smallest_subarray_covering_set(paragraph, keywords):\n",
    "    para_word_list = paragraph.split(\" \")\n",
    "    keywords_to_cover = collections.Counter(keywords)\n",
    "    #print(keywords_to_cover)\n",
    "    result = Subarray(-1, -1)\n",
    "    remaining_to_cover = len(keywords)\n",
    "    left = 0\n",
    "    for right, p in enumerate(para_word_list):\n",
    "        #print(f'right={right}, p={p} remaining={remaining_to_cover}')\n",
    "        if p in keywords:\n",
    "            keywords_to_cover[p] -= 1\n",
    "            if keywords_to_cover[p] == 0:\n",
    "                remaining_to_cover -= 1\n",
    "                #print(f'right={right}, p={p} remaining={remaining_to_cover}')\n",
    "        # Keep advancing left until we find the min subarray that covers the set and also we place left such that it no longer convers the entire set\n",
    "        while remaining_to_cover == 0:\n",
    "            if (result == (-1, -1)) or ((right - left) < result[1] - result[0]):\n",
    "                result = (left, right) # update result to store the indices of the smallest subarray that covers the set\n",
    "            pl = para_word_list[left]\n",
    "            if pl in keywords:\n",
    "                keywords_to_cover[pl] += 1\n",
    "                if keywords_to_cover[pl] > 0:\n",
    "                    remaining_to_cover += 1\n",
    "            left += 1\n",
    "    return result\n",
    "\n",
    "paragraph = \"apple banana apple apple dog cat apple dog banana apple cat dog\"                \n",
    "keywords = [\"banana\", \"cat\"]\n",
    "print(f'The smallest subarray is {find_smallest_subarray_covering_set(paragraph, keywords)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple': 1, 'banana': 1, 'dog': 1, 'cat': 1}\n",
      "{'apple': 1, 'banana': 0, 'dog': 0, 'cat': 0}\n",
      "The smallest subarray is None\n"
     ]
    }
   ],
   "source": [
    "# variant: Given an array A, find a shortest subarray A[i, j] such that each distinct value present in A is also present in the subarray.\n",
    "# Incomplete\n",
    "import collections\n",
    "Subarray = collections.namedtuple('Subarray',('start','end'))\n",
    "def find_smallest_subarray_covering_distinct_words(paragraph):\n",
    "    para_word_list = paragraph.split(\" \")\n",
    "    result = Subarray(-1, -1)\n",
    "    \n",
    "    word_dict = {}\n",
    "    for right, para in enumerate(para_word_list):\n",
    "        if not para in word_dict:\n",
    "            word_dict[para] = 1\n",
    "    print(word_dict)   \n",
    "    remaining_words_to_cover = len(word_dict)\n",
    "    left = 0\n",
    "    for right, para in enumerate(para_word_list):\n",
    "        if para in word_dict and word_dict[para] == 1:\n",
    "            remaining_words_to_cover -= 1\n",
    "            word_dict[para] -= 1\n",
    "        \n",
    "        while(remaining_words_to_cover == 0):\n",
    "            if (result == (-1, -1)) or ((right - left) < result[1] - result[0]):\n",
    "                result = (left, right) # update result to store the indices of the smallest subarray that covers the set\n",
    "            pl = para_word_list[left]\n",
    "            if pl in word_dict and word_dict[pl] == 0:\n",
    "                word_dict[pl] += 1\n",
    "                remaining_words_to_cover += 1\n",
    "            left += 1\n",
    "            \n",
    "            \n",
    "    print(word_dict)\n",
    "    #remaining_words_to_cover = len(word_dict)\n",
    "    #left = 0\n",
    "    #for right, p in enumerate(para_word_list):\n",
    "        \n",
    "paragraph = \"apple banana apple apple dog cat apple dog banana apple cat dog\"\n",
    "print(f'The smallest subarray is {find_smallest_subarray_covering_distinct_words(paragraph)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.7 Find smallest subarray sequentially covering all values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices of the shortest subarray covering the keywords sequentially is Subarray(start=1, end=3)\n"
     ]
    }
   ],
   "source": [
    "# Task: Write a program that takes two arrays of strings, and return the indices of the starting and ending\n",
    "# index of a shortest subarray of the first array (the \"paragraph\" array) that \"sequentially covers\",\n",
    "# i.e., contains all the strings in the second array (the \"keywords\" array), in the order in which they\n",
    "# appear in the keywords array. You can assume all keywords are distinct\n",
    "\n",
    "# Brute Force: check if keywords occur sequentially in each subarray => Time complexity:O(n^3)\n",
    "\n",
    "# Approach: Use hash tables: \n",
    "# 1.{keyword:keyword_index_in_keywords_array}, \n",
    "# 2.{keyword_index_in_keywords_array:keyword_latest_occurence_ind_in_para}, \n",
    "# 3.{keyword_index_in_keywords_array:shortest_subarray_length}\n",
    "import collections\n",
    "Subarray = collections.namedtuple('Subarray',('start','end'))\n",
    "# Time Complexity: O(N) where N is the length of the paragraph array.\n",
    "# Space Complexity: O(m) where m is the number of keywords - which is used by the three hash tables\n",
    "def find_smallest_sequentially_covering_subarray(paragraph, keywords):\n",
    "    paragraph_words = paragraph.split(\" \")\n",
    "    #print(f'para:{paragraph_words}')\n",
    "    keyword_to_idx = {k: i for i, k in enumerate(keywords)} # hashtable that stores {keyword:index} \n",
    "    \n",
    "    latest_occurence = [-1] * len(keywords) # stores the index at which a keyword occured recently in the paragraph\n",
    "    shortest_subarray_length = [float('inf')] * len(keywords) # shortest sub array length at the index where a keyword occured recently\n",
    "    \n",
    "    shortest_distance = float('inf')\n",
    "    result = Subarray(-1, -1)\n",
    "    for i, p in enumerate(paragraph_words):\n",
    "        if p in keyword_to_idx:\n",
    "            keyword_idx = keyword_to_idx[p]\n",
    "            latest_occurence[keyword_idx] = i # update the latest occurence index for the keyword\n",
    "            if(keyword_idx == 0): # first keyword\n",
    "                shortest_subarray_length[keyword_idx] = 1\n",
    "            elif shortest_subarray_length[keyword_idx - 1] != float('inf'): # check if all the keywords occured at least once before this keyword\n",
    "                distance_to_previous_keyword = i - latest_occurence[keyword_idx - 1]\n",
    "                shortest_subarray_length[keyword_idx] = distance_to_previous_keyword + shortest_subarray_length[keyword_idx - 1]\n",
    "        \n",
    "            # check if all keywords got covered sequentially. If so, update the shortest_distance accordingly\n",
    "            if(keyword_idx == len(keywords)-1 and shortest_subarray_length[-1] < shortest_distance):\n",
    "                shortest_distance = shortest_subarray_length[-1]\n",
    "                result = Subarray(i - shortest_distance + 1, i)\n",
    "        \n",
    "    return result\n",
    "\n",
    "paragraph = \"apple banana cat apple\"\n",
    "keywords = [\"banana\", \"apple\"] # correct ans :[1,3], even though [0,1] covers keywords but it does not cover them sequentially\n",
    "print(f'The indices of the shortest subarray covering the keywords sequentially is {find_smallest_sequentially_covering_subarray(paragraph, keywords)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.8 Find the longest subarray with distinct entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the longest subarray with distinct entries is 5\n"
     ]
    }
   ],
   "source": [
    "# Task: Write a program that takes an array and returns the length of a longest subarray with the property that all its elements are distinct.\n",
    "# Brute Force: For each subarray, check if all the words in it are distict. Time Complexity:O(n^3)\n",
    "\n",
    "# Approrch: Suppose if i to j is the longest subarray with distinct entries and when j+1 comes in, two cases are possible:\n",
    "# - if j+1 is not present in the longest subarray, it gets appended to the longest subarray\n",
    "# - if j+1 is present in the longest subarray, then it gets appended to the subarray beginning at the most recent occurence of the keyword at j+1 till j+1\n",
    "# Time Complexity: O(N) \n",
    "def longest_subarray_with_distinct_entries(A):\n",
    "    most_recent_occurence = {} # hast table to store the index at which keyword occurred most recently\n",
    "    longest_dup_free_subarray_start_idx = result = 0\n",
    "    for i, a in enumerate(A):\n",
    "        if a in most_recent_occurence:\n",
    "            dup_idx = most_recent_occurence[a]\n",
    "            # check if a is present in the longest_subarary\n",
    "            if(dup_idx >= longest_dup_free_subarray_start_idx):\n",
    "                # changing the longest subarray we have till now - so check its length and if it is larger than result => update result\n",
    "                result = max(result, i - longest_dup_free_subarray_start_idx)\n",
    "                longest_dup_free_subarray_start_idx = dup_idx + 1 # starting a new subarray\n",
    "        most_recent_occurence[a] = i\n",
    "    return max(result, (len(A) - longest_dup_free_subarray_start_idx)) # comparing result with last subarry\n",
    "\n",
    "A = ['f','s','f','e','t','w','e','n','w','e']\n",
    "print(f'The length of the longest subarray with distinct entries is {longest_subarray_with_distinct_entries(A)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.9 Find the length of a longest contained interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of longest contained interval is 4\n"
     ]
    }
   ],
   "source": [
    "# Task: Write a program which takes as input a set of integers represented by an array, and returns the size of a largest subset of integers in the array having the property that if two integers are in the subset, then so are all integers between them.\n",
    "# Example: Input:(3,-2,7,9,8,7,2,0, -1,5,8) Largest subset:{-2,-1,0,1,2,3} should return 6\n",
    "\n",
    "# Brute Force: Sort the array and then iterate through it, recording for each entry the largest subset with the desired property ending at that entry\n",
    "\n",
    "# Approach: Put distinc elements of the input array in a set. Pick an element, search for element-1 and element +1 if found remove those from set and keep on searching\n",
    "# Time Complexity: O(N) where N is the size of the input array. We add elemets to set one time and remove elements from the set one time.\n",
    "def longest_contained_range(A):\n",
    "    unprocessed_entries = set(A)\n",
    "    \n",
    "    max_interval_size = 0\n",
    "    while unprocessed_entries:\n",
    "        a = unprocessed_entries.pop()\n",
    "        # search if values on both sides of a are present in the set\n",
    "        lower_bound = a - 1# first search for a-1, if a-1 is present then search for a-2, and so on\n",
    "        while lower_bound in unprocessed_entries:\n",
    "            unprocessed_entries.remove(lower_bound) # Calculating interval using this will result in same result - so removing it\n",
    "            lower_bound -= 1\n",
    "        upper_bound = a + 1 # search for a+1, if a+1 is present then search for a+2 and so on\n",
    "        while upper_bound in unprocessed_entries:\n",
    "            unprocessed_entries.remove(upper_bound)# Calculating interval using this will result in same result - so removing it\n",
    "            upper_bound += 1\n",
    "        max_interval_size = max(max_interval_size, upper_bound - lower_bound - 1)\n",
    "    \n",
    "    return max_interval_size\n",
    "            \n",
    "A = [10, 5, 3, 11, 6, 100, 4]\n",
    "print(f'The length of longest contained interval is {longest_contained_range(A)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.10 Compute all string decompositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The substring indices are :None\n"
     ]
    }
   ],
   "source": [
    "# Write a program which takes as input a string (the \"sentence\") and an array of strings (the \"words\"), and returns the starting indices of substrings of the sentence string which are the concatenation\n",
    "# of all the strings in the words array. Order concatenation of words is immaterial. All words should appear once in the concatenation.\n",
    "\n",
    "# Brute Force:  #Incomplete\n",
    "\n",
    "def find_all_substrings(s, words):\n",
    "    def match_all_words_in_dict(start):\n",
    "        curr_string_to_freq = collections.Counter()\n",
    "        for i in range(start, start + len(words) * unit_size, unit_size):\n",
    "            curr_word = s[i:i + unit_size]\n",
    "            it = word_to_freq[curr_word]\n",
    "            if it == 0:\n",
    "                return False\n",
    "            curr_string_to_freq[curr_word] += 1\n",
    "            if curr_string_to_freq[curr_word] > it:\n",
    "                return False\n",
    "            return True\n",
    "    word_to_freq = collections.Counter(words)\n",
    "    unit_size = len(words[0])\n",
    "    return [i for i in range(len(s) - unit_size * len*(words) + 1) if match_all_words_in_dict(i)]\n",
    "\n",
    "sentence = \"amanaplanacanal\"\n",
    "words = [\"can\", \"apl\", \"ana\"]\n",
    "print(f'The substring indices are :{find_all_substrings(sentence, words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.11 Test the collatz conjecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# The Collatz conjecture is the following: Take any natural number. If it is odd, triple it and add one;\n",
    "# if it is even, halve it. Repeat the process indefinitely. No matter what number you begin with, you\n",
    "# will eventually arrive at 1.\n",
    "\n",
    "# Task: Test the Collatz conjecture for the first n positive integers\n",
    "# Brute Force: Generate convergence seq for each number and then return True if the seq converges at 1 for each of them.\n",
    "# Another Approach: The question is open-ended - so just give a good heuristic and code it well\n",
    "# Collatz hypothesis can fail in two ways\n",
    "# -a sequence returns to a previous number in the sequence, which implies it will loop forever,(save all numbers encountered in a set)\n",
    "# - or a sequence goes to infinity.(overflow)\n",
    "# The following tricks can be used to speedup computation:\n",
    "# - if even number skip the check as it is immediately divided by 2.\n",
    "# - save all the already verified numbers that converges to 1 in a set \n",
    "def test_collatz_conjecture(n):\n",
    "    verified_numbers = set() # stores odd numbers already tested to converge to 1\n",
    "    \n",
    "    for i in range(3, n+1):\n",
    "        sequence = set()\n",
    "        test_i = i\n",
    "        while test_i >= i:\n",
    "            if test_i in sequence:\n",
    "                return False # encountered number that is already visited - infinite loop\n",
    "            sequence.add(test_i)\n",
    "            if test_i % 2: #odd number\n",
    "                if test_i in verified_numbers:\n",
    "                    break\n",
    "                verified_numbers.add(test_i)\n",
    "                test_i = 3 * test_i + 1\n",
    "            else:\n",
    "                test_i //= 2\n",
    "    return True\n",
    "\n",
    "print(test_collatz_conjecture(11))\n",
    "print(test_collatz_conjecture(100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
